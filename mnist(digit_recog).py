# -*- coding: utf-8 -*-
"""MNIST(digit-recog).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YIM2xPtnf8VTgyOdahS4KY359cSfWK2E
"""

import tensorflow

from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Flatten
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

#importing the MNIST Dataset
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

#x consists of 3D arrays as numeric images whereas Y consists of label corresponding to the X image.
x_train.shape, x_test.shape, y_train.shape

#viewing the imported MNIST data
plt.imshow(x_train[4])
print(y_train[4])

x_train[2]

#the value of an image array ranges from 0 to 255. We have to convert the values to range from 0 to 1.
x_train = x_train/255
x_test = x_test/255

x_train[2]

model = Sequential()

model.add(Flatten(input_shape=(28,28)))                      #adding first layer by flattening the 28 by 28 pixel image
model.add(Dense(128, activation='relu'))                     #adding second layer i.e. hidden layer
model.add(Dense(10, activation='softmax'))                   #adding output layer

model.summary()

#defining a loss function and an optimizer for the model
model.compile(loss='sparse_categorical_crossentropy',
              optimizer='Adam')

mdl = model.fit(x_train, y_train, epochs=10, validation_split=0.2)

y_prob = model.predict(x_test)

y_pred = y_prob.argmax(axis=1)   #gives the exact predicted labels

y_pred #predicted labels

y_test #actual labels

model.predict(x_test[5]).argmax(axis=1)          #testing the model

y_test[5]

#checking models accuracy
accuracy_score(y_test, y_pred)

plt.plot(mdl.history['loss'])
plt.plot(mdl.history['val_loss'])

plt.imshow(x_test[100])

model.predict(x_test[100]).argmax(axis=1) #hence the model predicts the number correctly

